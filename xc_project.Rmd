---
title: "Extra Credit Project"
author: "Marc Luiz, Nelly Shieh, Jeff Nguyen"
date: "18/09/2020"
output:
  pdf_document: default
  html_document:
    code_folding: "hide"
  word_document: default
---
```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning=FALSE, message=FALSE) 
```

**Coitegration Analysis of Different Financial Markets**  
**University of Southern California**  
**Marshall School of Business**  
**FBE 543 Forecasting and Risk Analysis**  
**Spring 2021**  
**Directed by Professor Mohammad Safarzadeh**   
  
# Topic:  
Using major stock indices for the United States (S&P500), Unite Kingdom (FTSE100), Germany (DAX), and France (CAC40) show that US and European financial markets cointegrate.  

# Method:  
**Reviewing cointegration condition:**    

Consider 2 time series variables $Y$ and $X$. We have the regression equation as follow:  

\begin{equation}
  \begin{aligned}
    Y_t =& \beta_0 + \beta_1 X_t + \epsilon_t  \\
  \end{aligned}
\end{equation}
  
The cointegration is such that if $X$ and $Y$ are both non-stationary variables AND $\epsilon$ is a stationary variable, then $X$ and $Y$ cointegrate, i.e. they "move together" in the long run.  

Thus, our primary methodology is as follow:  

## 1. Test indices for stationarity:  
Test representative stock indices in the United States (S&P 500), the United Kingdom (FTSE), Germany (DAX) and France (CAC40) for stationarity.  
To execute this task, for each indices, we run the Augmented Dickey-Fuller Test (A)DF, which hypothesizes that a unit root is present in an autoregressive model. The intuition is such that if a variable is stationary, it tends to a constant mean--i.e. the values oscillates/ alternate for large to small. As a result, the process is not a random walk, i.e. nonstationary.

## 2. Test error term for stationarity:  
Should the regressed result confirm non-stationarity, check whether the error term of the regression $\epsilon$ are non-stationary variables. If they are, then the indices cointegrate.  
  
First we check for the common issue with time series data: positive autocorrelation by running Durbin-Watson Test. If autocorrelation exists, we add the first order autoregressive term $AR(1)$ into the model and subsequently $AR(2)$ as necessary.

Then, we run (A)DF test as above to test the error term for stationarity--not having a unit root in the (A)DF test.  

# Data Analysis  

For this model, we use 20 years of data from March 2001 to March 2021.  
  
## Downloading data  

```{r}
library(quantmod)

# Set start date and end date of data
start_date <- "2001-01-01"
end_date <- "2021-03-18"

# Get data
getSymbols("^GSPC", src = "yahoo", , from = start_date, to = end_date) # S&P 500
getSymbols("^FTSE", src = "yahoo", , from = start_date, to = end_date) # S&P 500
getSymbols("^GDAXI", src = "yahoo", , from = start_date, to = end_date) # S&P 500
getSymbols("^FCHI", src = "yahoo", , from = start_date, to = end_date) # S&P 500

# Adjusted Prices
adjGSPC_mo <- to.monthly(GSPC)$GSPC.Adjusted
adjFTSE_mo <- to.monthly(FTSE)$FTSE.Adjusted
adjGDAXI_mo <- to.monthly(GDAXI)$GDAXI.Adjusted
adjFCHI_mo <- to.monthly(FCHI)$FCHI.Adjusted

# Merge xts object
globalIndices <- merge.xts(adjGSPC_mo)
```
  
## Data Observation:  

Observing each indices:  
```{r}
library(forecast)

ggtsdisplay(adjGSPC_mo, main="S&P 500", plot.type="scatter")
ggtsdisplay(adjFTSE_mo, main="FTSE 100", plot.type="scatter")
ggtsdisplay(adjGDAXI_mo, main="DAX 30", plot.type="scatter")
ggtsdisplay(adjFCHI_mo, main="CAC 40", plot.type="scatter")
```
  
**Remarks**  
We can also see all indices' lag plots exhibit a linear pattern, implying that the data are strongly non-random and thus, a first-order autoregressive model might be appropriate.  

\begin{equation}
  \begin{aligned}
    y_t =& \beta_0 + \beta_1 y_{t-1} + \epsilon_t
  \end{aligned}
\end{equation}
  
## Testing for Stationarity for indices
  
Per methodology, we run Augmented Dickey Fuller Test for each indices. Recall that the null hypothesis for Dickey-Fuller Test is that a unit root is present in our autoregressive model, meaning the variable is a non-stationary variable.  
  
### S&P 500  

```{r}
library(aTSA)

adf.test(adjGSPC_mo)
```
  
We can observe $p-value = .99 > .05$. Thus, we fail to reject the null hypothesis. In other words, S&P 500 monthly adjusted closing price has a unit root and therefore, is a non-stationary variable.
  

### FTSE 100  

```{r}
adf.test(adjFTSE_mo)
```
  
We can observe $p-value > .05$. Thus, we fail to reject the null hypothesis. In other words, FTSE100 monthly adjusted closing price has a unit root and therefore, is a non-stationary variable.
  
### DAX 30  

```{r}
adf.test(adjGDAXI_mo)
```
  
We can observe $p-value = .99 > .05$. Thus, we fail to reject the null hypothesis. In other words, DAX 30 monthly adjusted closing price has a unit root and therefore, is a non-stationary variable.
  
### CAC 40  

```{r}
adf.test(adjFCHI_mo)
```
  
We can observe $p-value > .05$. Thus, we fail to reject the null hypothesis. In other words, CAC 40 monthly adjusted closing price has a unit root and therefore, is a non-stationary variable.
  
### Remarks  
**Through (A)DF tests, we can observe that the indices adjusted monthly closing prices are non-stationary variables.**
  
## Testing for stationarity for error term  

Regression model  

```{r}
# Converting xts to numeric because DW doesn't play nice with xts
adjGSPC_mo_num <- as.numeric(adjGSPC_mo)
adjFTSE_mo_num <- as.numeric(adjFTSE_mo)
adjGDAXI_mo_num <- as.numeric(adjGDAXI_mo)
adjFCHI_mo_num <- as.numeric(adjFCHI_mo)

model1 <- lm(adjGSPC_mo_num ~ adjFTSE_mo_num + adjGDAXI_mo_num + adjFCHI_mo_num, data=globalIndices)
model1
```
### Checking for positive autocorrelation  

We first run Durbin-Watson Test to check for positive autocorrelation.
  
```{r}
library(car)

durbinWatsonTest(model1, max.lag=4)
```
  
We can observe $p-value < .05$ from the DW Test, implying autocorrelation of the residuals in this model. We will attempt to remedy by apply an ARIMA model.

### Fitting ARIMA Model  

```{r}
model2 <- auto.arima(adjGSPC_mo)
summary(model2)
```
  
We can see that with $ARIMA(2,2,2)$, we have great $ACF1$ statistics, implying a good fit for forecasting.  

### Re-running Durbin Watson Test with ARIMA(2,2,2)  

We rerun the Durbin Watson Test to verify if autocorrelation has been fixed. Since $durbinWatsonTest$ requires a linear model object, we calculate the statistics using the following equation:  

\begin{equation}
  \begin{aligned}
    d =& \frac{\sum_{t=2}^T (\epsilon_t - \epsilon_{t-1})^2}{\sum_{t=1}^T \epsilon_t^2}  \\
      =& `r ( sum((model2$residuals - lag(model2$residuals))^2, na.rm=TRUE))/( sum(model2$residuals^2, na.rm=TRUE))` \approx 2 \\
  \end{aligned}
\end{equation}

Since the new Durbin-Watson Test is $d \approx 2$, we addressed the autocorrelation issue with our model.
  
### Test for stationarity of error term  

We run the (A)DF test to check for stationarity of the error terms:  

```{r}
adf.test(model2$residuals)
```
  
We can observe that $p-value = .01 < .05$, thus we reject the null hypothesis that the variable--the error term in this case--has a unit root. Thus the error term is non-stationary.

# Conclusion  

In conclusion, through our analysis, we note that all indices are stationary variables. However the error term is a stationary variable. This means that the global indices cointegrate.  
  

